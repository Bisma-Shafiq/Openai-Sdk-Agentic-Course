{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1GCUqXXMehc",
        "outputId": "57381457-9362-47ef-f715-bf428d455b10"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.3)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'd:/Crewai-Projects/openai-sdk-class/uv/AI-chatbot-project/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H7LBL7YGMi4C"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y6_wC79CMnyF"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import (\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    RunConfig)\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2SLBWrFzMq8z"
      },
      "outputs": [],
      "source": [
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j7YQtAruMtSM"
      },
      "outputs": [],
      "source": [
        "from agents import set_default_openai_client, set_tracing_disabled\n",
        "set_default_openai_client(external_client)\n",
        "set_tracing_disabled(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuhSXpItMwXr",
        "outputId": "b36f56e3-29e4-4ad0-ee48-f44389c619da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The user is 89 years old. I do not have the ability to determine their current location.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo1:\n",
        "    name: str\n",
        "    uid: int\n",
        "    location: str = \"UMT\"\n",
        "\n",
        "@function_tool\n",
        "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the age of the user.'''\n",
        "    return f\"User {wrapper.context.name} is 89 years old\"\n",
        "\n",
        "@function_tool\n",
        "async def fetch_user_location(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the location of the user.'''\n",
        "    return f\"User {wrapper.context.name} is from {wrapper.context.location}\"\n",
        "\n",
        "async def main():\n",
        "    user_info = UserInfo1(name=\"ABCDEF\", uid=123)\n",
        "\n",
        "    agent = Agent[UserInfo1](\n",
        "        name=\"Assistant\",\n",
        "        tools=[fetch_user_age],\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"What is the age of the user? current location of his/her?\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "    # The user John is 47 years old.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_TXJkLSRPAd"
      },
      "source": [
        "### LLM/cotext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrYtk84gN996",
        "outputId": "012a666e-9741-4764-9398-0cb51e93e490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello Muhammad Qasim, Welcome to Panaversity! Your skills are Python and Java.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo:\n",
        "    name: str\n",
        "    uid: int\n",
        "\n",
        "@dataclass\n",
        "class Skill:\n",
        "  skills: list[str]\n",
        "\n",
        "@function_tool\n",
        "async def greet_user(context: RunContextWrapper, greeting: str) -> str:\n",
        "  \"\"\"Greets the User with their name.\n",
        "  Args:\n",
        "    greeting: A specialed greeting message for user\n",
        "  \"\"\"\n",
        "  name = context.context[0].name\n",
        "  skills = context.context[1].skills\n",
        "  return f\"Hello {name}, {greeting}, {skills}\"\n",
        "\n",
        "async def main():\n",
        "    user_info = UserInfo(name=\"ABCDEF\", uid=123)\n",
        "    skills = Skill(skills=[\"Python\", \"Java\"])\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        tools=[greet_user],\n",
        "        model=model,\n",
        "        # Dynamic function context pass in instructions/system prompmt/developer prompt\n",
        "        instructions=\"Always greet the user using <function_call>greet_user</function_call> and welcome them to Panaversity\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Hello what are the user skills and their name\",\n",
        "        context=[user_info,skills]\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJvYecOQ250O"
      },
      "source": [
        "#### Handoff with context"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
